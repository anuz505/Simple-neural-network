{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Change the Runtime to GPU\n",
        "\n",
        "Runtime -> Change runtime type -> \"T4 GPU\" -> Save"
      ],
      "metadata": {
        "id": "54W3FHnkmV8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Importing the Segmentation Dataset"
      ],
      "metadata": {
        "id": "ffyxT_9bUmXx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXn2tkERUQ66"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the content of the dataset\n",
        "\n",
        "### Start Code Here\n",
        "!ls >>>path_to_dataset<<<\n",
        "### End"
      ],
      "metadata": {
        "id": "ooaf4IWrUgk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"dark_background\")"
      ],
      "metadata": {
        "id": "0gFCE720VCdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Start Code Here\n",
        "ROOT_DIR = >>>path_to_dataset<<<\n",
        "### End"
      ],
      "metadata": {
        "id": "wWRR8k84jIbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make objects with the images and masks\n",
        "import glob\n",
        "\n",
        "brain_scans = []\n",
        "mask_files = glob.glob(f'{ROOT_DIR}/*/*_mask*')\n",
        "\n",
        "for i in mask_files:\n",
        "    brain_scans.append(i.replace('_mask',''))\n",
        "\n",
        "# Print 10 input and mask files\n",
        "print(brain_scans[:10])\n",
        "print(mask_files[:10])"
      ],
      "metadata": {
        "id": "ugyj-8itVbi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a dataframe with the images and their corresponding masks\n",
        "import pandas as pd\n",
        "\n",
        "### Start Code Here\n",
        "img_df = pd.DataFrame({\n",
        "    \"image_path\":>>>brain_scans<<<,\n",
        "    \"mask_path\":>>>mask_files<<<\n",
        "})\n",
        "### End\n",
        "print(img_df.head(5))"
      ],
      "metadata": {
        "id": "T_O-ekLNVdjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Adding A/B column for diagnosis\n",
        "def positiv_negativ_diagnosis(mask_path):\n",
        "    value = np.max(cv2.imread(mask_path))\n",
        "    if value > 0 : return 1\n",
        "    else: return 0# How many non-tumors (0) and tumors (1) are in the data\n",
        "\n",
        "def process_images(mask_paths):\n",
        "    results = []\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        results = list(tqdm(executor.map(positiv_negativ_diagnosis, mask_paths), total=len(mask_paths)))\n",
        "    return results\n",
        "\n",
        "# Apply the function to the masks and return back a column with 1 and zeros, where 0 indicates no tumor and 1 a tumor\n",
        "img_df[\"diagnosis\"] = process_images(img_df[\"mask_path\"].tolist())\n",
        "img_df.head()"
      ],
      "metadata": {
        "id": "uzV1cCJNVomM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Visualization"
      ],
      "metadata": {
        "id": "plIjtgVKVt78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many non-tumors (0) and tumors (1) are in the data\n",
        "img_df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "id": "b3RgsoEHVrhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the MRI, Mask and overlay image"
      ],
      "metadata": {
        "id": "z1jKz2JsZDxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.axes_grid1.axes_grid import ImageGrid\n",
        "# Data\n",
        "sample_df = img_df[img_df[\"diagnosis\"] == 1].sample(5).values\n",
        "sample_imgs = []\n",
        "\n",
        "for i, data in enumerate(sample_df):\n",
        "    img = cv2.resize(cv2.imread(data[0]), (256, 256))\n",
        "    mask = cv2.resize(cv2.imread(data[1]), (256, 256))\n",
        "     # Plot the Brain MRI scan with their mask\n",
        "    main = img.copy()\n",
        "    sample = np.array(np.squeeze(mask), dtype = np.uint8)\n",
        "    contours, hier = cv2.findContours(sample[:,:,0],cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    sample_over_gt = cv2.drawContours(main, contours, -1,[255,0,0], thickness=-1)\n",
        "\n",
        "    sample_imgs.extend([img, mask, sample_over_gt])\n",
        "\n",
        "sample_imgs_arr = np.hstack(np.array(sample_imgs[::3]))\n",
        "sample_masks_arr = np.hstack(np.array(sample_imgs[1::3]))\n",
        "sample_over_gt_arr = np.hstack(np.array(sample_imgs[2::3]))\n",
        "\n",
        "# Plot\n",
        "fig = plt.figure(figsize=(25., 25.))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(3, 1),  # creates 3x1 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "grid[0].imshow(sample_imgs_arr)\n",
        "grid[0].set_title(\"Images\", fontsize=15)\n",
        "grid[0].axis(\"off\")\n",
        "\n",
        "grid[1].imshow(sample_masks_arr)\n",
        "grid[1].set_title(\"Masks\", fontsize=15, y=0.9)\n",
        "grid[1].axis(\"off\")\n",
        "\n",
        "grid[2].imshow(sample_over_gt_arr)\n",
        "grid[2].set_title(\"MRI Brain with highlighted Tumor\", fontsize=15)\n",
        "grid[2].axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E9dEHZNUY-Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Dataset split and DataLoaders"
      ],
      "metadata": {
        "id": "mmgRqkO3ZXZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class BrainMRIDataset(Dataset):\n",
        "    def __init__(self, df, transforms):\n",
        "\n",
        "        self.df = df\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = cv2.imread(self.df.iloc[idx, 0])\n",
        "        mask = cv2.imread(self.df.iloc[idx, 1], 0)\n",
        "\n",
        "        # Normalize mask from 0-255 to 0-1\n",
        "        ### Start Code Here\n",
        "        mask = >>>image_nomrmalization<<<\n",
        "\n",
        "        augmented = self.transforms(\n",
        "            >>>image<<<,\n",
        "            >>>mask<<<\n",
        "            )\n",
        "        ### End\n",
        "\n",
        "        image = augmented['image']\n",
        "        mask = augmented['mask']\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "n4LkBd0eZTbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image transformation"
      ],
      "metadata": {
        "id": "DXWRBFpTZ-Vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Start Code Here\n",
        "transforms = A.Compose([\n",
        "    >>>horizontal_flip<<<,\n",
        "    >>>vertical_flip<<<,\n",
        "    >>>random_rotate_90<<<,\n",
        "    >>>transpose<<<,\n",
        "    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n",
        "    A.Normalize(p=1.0),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "### End"
      ],
      "metadata": {
        "id": "oXajXhKYaAYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and test data split"
      ],
      "metadata": {
        "id": "SlgvF5CJaXNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Start Code Here\n",
        "# Split df into train_df and val_df\n",
        "train_df, val_df = >>>train_val_split<<<\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "\n",
        "# Split train_df into train_df and test_df\n",
        "train_df, test_df = >>>train_test_split<<<\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "### End\n",
        "#train_df = train_df[:1000]\n",
        "print(f\"Train: {train_df.shape} \\nVal: {val_df.shape} \\nTest: {test_df.shape}\")"
      ],
      "metadata": {
        "id": "-EUW7hViaQkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "EypGD7cublpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "import multiprocessing\n",
        "num_workers = multiprocessing.cpu_count()\n",
        "batch_size = 4\n",
        "\n",
        "### Start Code Here\n",
        "train_dataset = BrainMRIDataset(df=train_df, transforms=transforms)\n",
        "train_dataloader = >>>train_dataloader<<<\n",
        "\n",
        "# val\n",
        "val_dataset = >>>val_dataset<<<\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "\n",
        "#test\n",
        "test_dataset = >>>test_dataset<<<\n",
        "test_dataloader = >>>test_dataloader<<<\n",
        "### End"
      ],
      "metadata": {
        "id": "wbAHyCAXbla6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. UNet Model"
      ],
      "metadata": {
        "id": "LtxOV814b8f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "DEVICE = >>>assign_to_cuda_if_available<<<\n"
      ],
      "metadata": {
        "id": "Tt0vqNoxb1ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VanillaUNet(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        ### Start Code Here\n",
        "        self.conv_down1 = self.double_conv(3, >>>output_channel<<<)\n",
        "        self.conv_down2 = self.double_conv(>>>in_channel<<<, 128)\n",
        "        self.conv_down3 = self.double_conv(128, 256)\n",
        "        self.conv_down4 = self.double_conv(256,>>>out_channel<<<)\n",
        "        ### End\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.conv_up3 = self.double_conv(256 + 512, 256)\n",
        "        self.conv_up2 = self.double_conv(128 + 256, 128)\n",
        "        self.conv_up1 = self.double_conv(128 + 64, 64)\n",
        "\n",
        "        self.last_conv = nn.Conv2d(64, n_classes, kernel_size=1)\n",
        "\n",
        "    def double_conv(self, in_channels, out_channels):\n",
        "        ### Start Code Here\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, >>>kernel_size<<<, padding=>>>padding_size<<<),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, >>>kernel_size<<<, padding=>>>padding_size<<<),\n",
        "            >>>relu operation<<<<,\n",
        "            )\n",
        "        ### End\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Batch - 1d tensor.  N_channels - 1d tensor, IMG_SIZE - 2d tensor.\n",
        "        # Example: x.shape >>> (10, 3, 256, 256).\n",
        "        ### Start Code Here\n",
        "        conv1 = >>>output_of_the_first_double_convolution<<<    # <- BATCH, 3,   IMG_SIZE -> BATCH,  64, IMG_SIZE..\n",
        "        x     = self.maxpool(conv1)                             # <- BATCH, 64,  IMG_SIZE -> BATCH,  64, IMG_SIZE 2x down.\n",
        "        conv2 = self.conv_down2(x)                              # <- BATCH, 64,  IMG_SIZE -> BATCH, 128, IMG_SIZE.\n",
        "        x     = self.maxpool(conv2)                             # <- BATCH, 128, IMG_SIZE -> BATCH, 128, IMG_SIZE 2x down.\n",
        "        conv3 = self.conv_down3(x)                              # <- BATCH, 128, IMG_SIZE -> BATCH, 256, IMG_SIZE.\n",
        "        x     = >>>max_pooling_operation<<<<                    # <- BATCH, 256, IMG_SIZE -> BATCH, 256, IMG_SIZE 2x down.\n",
        "        x     = self.conv_down4(x)                              # <- BATCH, 256, IMG_SIZE -> BATCH, 512, IMG_SIZE.\n",
        "        x     = self.upsample(x)                                # <- BATCH, 512, IMG_SIZE -> BATCH, 512, IMG_SIZE 2x up.\n",
        "\n",
        "        #(Below the same)                                 N this       ==        N this.  Because the first N is upsampled.\n",
        "        x    = >>>concatenation_of_the_two_feature<<<<         # <- BATCH, 512, IMG_SIZE & BATCH, 256, IMG_SIZE--> BATCH, 768, IMG_SIZE.\n",
        "\n",
        "        x    = self.conv_up3(x)                                 #  <- BATCH, 768, IMG_SIZE --> BATCH, 256, IMG_SIZE.\n",
        "        x    = self.upsample(x)                                 #  <- BATCH, 256, IMG_SIZE -> BATCH,  256, IMG_SIZE 2x up.\n",
        "        x    = torch.cat([x, conv2], dim=1)                     # <- BATCH, 256,IMG_SIZE & BATCH, 128, IMG_SIZE --> BATCH, 384, IMG_SIZE.\n",
        "\n",
        "        x    = self.conv_up2(x)                                 # <- BATCH, 384, IMG_SIZE --> BATCH, 128 IMG_SIZE.\n",
        "        x    = self.upsample(x)                                 # <- BATCH, 128, IMG_SIZE --> BATCH, 128, IMG_SIZE 2x up.\n",
        "        x    = torch.cat([x, conv1], dim=1)                     # <- BATCH, 128, IMG_SIZE & BATCH, 64, IMG_SIZE --> BATCH, 192, IMG_SIZE.\n",
        "\n",
        "        x    = self.conv_up1(x)                                 # <- BATCH, 128, IMG_SIZE --> BATCH, 64, IMG_SIZE.\n",
        "\n",
        "        out  = self.last_conv(x)                                # <- BATCH, 64, IMG_SIZE --> BATCH, n_classes, IMG_SIZE.\n",
        "\n",
        "\n",
        "        >>>sigmoid_of_the_output_logits<<<\n",
        "        ### End\n",
        "        return out"
      ],
      "metadata": {
        "id": "-A_I17qFcC3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model visualization"
      ],
      "metadata": {
        "id": "r1eti3R1dPz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = VanillaUNet(n_classes=1).to(DEVICE)\n",
        "### Start Code Here\n",
        "output = model(torch.randn([>>>input_shape<<<]).to(DEVICE))\n",
        "print(>>>output_shape<<<)\n",
        "### End"
      ],
      "metadata": {
        "id": "b-6yRsPudSO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "### Start Code Here\n",
        ">>>summary_of_the_model<<<\n",
        "### End"
      ],
      "metadata": {
        "id": "lwYt2Azldhpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef_loss(inputs, target):\n",
        "    smooth = 1.0\n",
        "    intersection = 2.0 * ((target * inputs).sum()) + smooth\n",
        "    union = target.sum() + inputs.sum() + smooth\n",
        "\n",
        "    return 1 - (intersection / union)\n",
        "\n",
        "### Start Code Here\n",
        "def bce_dice_loss(inputs, target):\n",
        "    dicescore = dice_coef_loss(inputs, target)\n",
        "    bcescore = >>>PyTorch_BCE_loss<<<\n",
        "    bceloss = bcescore(inputs, target)\n",
        "\n",
        "    return bceloss + dicescore\n",
        "### End\n",
        "\n",
        "loss_fn = bce_dice_loss"
      ],
      "metadata": {
        "id": "6Wzm73T5dnM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "f3AeP6OVeRU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, loss_fn, optimizer, train_dataloader):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "\n",
        "    print(\"Training Phase ...\")\n",
        "    pbar = tqdm(range(len(train_dataloader)))\n",
        "    for data, labels in train_dataloader:\n",
        "        ### Start Code Here\n",
        "        data = data.to(>>>device<<<)\n",
        "        labels = labels.to(>>>device<<<)  # Convert labels to Float\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        >>>pass_the_data_through_the model<<<\n",
        "        logits = >>>model<<<\n",
        "\n",
        "        loss = loss_fn(logits.squeeze(1), labels.float())\n",
        "        >>>add_loss<<<<\n",
        "\n",
        "        >>>back_propagation<<<\n",
        "        ### End\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        pbar.update()\n",
        "\n",
        "    return losses / len(train_dataloader)\n",
        "\n",
        "def evaluate_model(model, loss_fn, val_dataloader):\n",
        "    ### Start Code Here\n",
        "    >>>change_the_model_to_eval_mode<<<<\n",
        "    losses = 0\n",
        "\n",
        "    print(\"Validation Phase ...\")\n",
        "    qbar = tqdm(range(len(val_dataloader)))\n",
        "    for data, labels in val_dataloader:\n",
        "        data = data.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)  # Convert labels to Float\n",
        "\n",
        "        logits = model(data)\n",
        "\n",
        "        >>>loss_calculation_and_add_to_losses<<<<\n",
        "        ### End\n",
        "        qbar.update()\n",
        "\n",
        "    return losses / len(val_dataloader)"
      ],
      "metadata": {
        "id": "G23XwmgMePU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define optimizer"
      ],
      "metadata": {
        "id": "7X60D3sRe3I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Start Code Here\n",
        ">>>define_the_optimizer <<<\n",
        "### End"
      ],
      "metadata": {
        "id": "If6QZ7dne001"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "Tq9xpHfae-cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "checkpoint_dir = \"checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"Epoch {epoch}/{epochs}\")\n",
        "    print(\"-\" * 10)\n",
        "    ### Start Code Here\n",
        "    >>>train_the_model<<<\n",
        "    >>>validate_the_model<<<\n",
        "\n",
        "    print(f\"Epoch: {epoch}, Train loss: {>>>train_loss <<< :.3f}, Val loss: {>>>validation_loss<<<:.3f}\")\n",
        "\n",
        "    # Save model checkpoint\n",
        "    torch.save(model.state_dict(), f'{checkpoint_dir}/unet_model_epoch_{epoch}.pth')\n",
        "\n",
        ">>>save_the_final_model<<<\n",
        "### End"
      ],
      "metadata": {
        "id": "rgUm_WT5e8F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### visualize the prediction"
      ],
      "metadata": {
        "id": "c00kqu90fWfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "### Start Code Here\n",
        "model = >>>load_the_model <<<<\n",
        "### End\n",
        "\n",
        "def inference_pipeline(model, test_dataloader, device, threshold=0.3):\n",
        "    ### Start Code Here\n",
        "    >>> convert_the_model_to_eval_mode <<<\n",
        "    with torch.no_grad():\n",
        "        for data, labels in test_dataloader:\n",
        "            data = data.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Get predictions\n",
        "            >>> run the inference <<<\n",
        "            >>> convert the prediction to numpy <<<<\n",
        "\n",
        "            # Apply threshold\n",
        "            preds_t = >>> process the prediction <<<)\n",
        "            ### End\n",
        "\n",
        "            # Plot results for the first batch\n",
        "            fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(15, 10))\n",
        "            for i in range(len(data)):\n",
        "                # Original image\n",
        "                img = data[i].permute(1, 2, 0).cpu().numpy()\n",
        "                img = (img - img.min()) / (img.max() - img.min())  # Normalize to [0, 1]\n",
        "                ax[0, i].imshow(img)\n",
        "                ax[0, i].set_title(\"Image\")\n",
        "                ax[0, i].axis(\"off\")\n",
        "\n",
        "                # Ground truth mask\n",
        "                ax[1, i].imshow(labels[i].cpu().numpy(), cmap='gray')\n",
        "                ax[1, i].set_title(\"Mask (GT)\")\n",
        "                ax[1, i].axis(\"off\")\n",
        "\n",
        "                # Prediction\n",
        "                ax[2, i].imshow(preds_t[i, 0, :, :], cmap='gray')\n",
        "                ax[2, i].set_title(\"Prediction\")\n",
        "                ax[2, i].axis(\"off\")\n",
        "                if i == 3:\n",
        "                    break\n",
        "\n",
        "            plt.show()\n",
        "            break"
      ],
      "metadata": {
        "id": "xov2N6tmfQBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the inference"
      ],
      "metadata": {
        "id": "VQ_9or-7ftN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Start Code Here\n",
        ">>> Load the saved  model <<<\n",
        ">>> run the inference <<<\n",
        "### End"
      ],
      "metadata": {
        "id": "lMvXkdYBfw4q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}